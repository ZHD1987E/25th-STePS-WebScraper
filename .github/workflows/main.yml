name: Run Python Script and Upload Output to Repo

on:
  push:
    branches:
      - main  # Trigger on pushes to the main branch
  schedule:
    - cron: '0/30 * * * *'  # Optionally, schedule to run daily at 2 a.m.

jobs:
  run_script:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2: Set up Python environment
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Run the Python script
      - name: Run the script
        run: python scraping.py

      # Step 5: Commit and push output file to GitHub
      - name: Commit and push output file to GitHub
        run: |

          git config --global user.name "Scraping Bot"
          git config --global user.email "zhanghaodong101@outlook.com"
          
          # Add the output file(s) to the repository
          git add "project names.md" "project videos.md"

          # Commit the changes
          git commit -m "Updating files automatically every 30 minutes"

          # Push the changes back to the repository
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
